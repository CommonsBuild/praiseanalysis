{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Praise by Words (ðŸ™octopus)\n",
    "\n",
    "**Date: June 9, 2011**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we will work to gain insight about the way in which different types of activities influence the distribution of Impact Hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages and Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df = pd.read_csv(\"cleaned-non-quantifier-data.csv\")\n",
    "praise_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a Feel for the Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before attempting a sophisticated algorithms, we want to do some human analysis in the data. We look at a large sample of \"Reason for Dishing\" to get a feel for the reasons that praise is given. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df[\"Reason for dishing\"].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing a Slight Bit of Cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will help to get consistency in the words. First, we make all of the strings lower case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lower_case = lambda x: x.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df[\"Reason for dishing\"] = praise_df[\"Reason for dishing\"].map(make_lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen before, the Impact Hours are quite right-skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df['IH per Praise'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's check for missing values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df['IH per Praise'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There appear to be several -- let's verify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df[praise_df['IH per Praise'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We drop these 502 missing values since they have no quantitative information.  We then re-set the index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.dropna(subset=[\"IH per Praise\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df[\"IH per Praise\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df = praise_df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Many of the columns will not be useful for this particular analysis. \n",
    "\n",
    "We drop all of the following:\n",
    "* To\n",
    "* From\n",
    "* v1 Norm\n",
    "* v2 Norm\n",
    "* v3 Norm\n",
    "* IH per Person\n",
    "* Cred per Praise\n",
    "* Cred per person\n",
    "* Period\n",
    "* Room (since we have Room-NoEmoji, which is cleaner)\n",
    "* v1\n",
    "* v2\n",
    "* v3\n",
    "* Cred per Praise\n",
    "* Cred per person\n",
    "* Unnamed: 12 (a duplicate of \"To\")\n",
    "* To.1\n",
    "\n",
    "We are focusing on other information for this analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.drop(inplace = True, columns = [\"To\", \"From\", \"v1 norm\", \"v2 norm\", \"v3 norm\", \"IH per person\", \"Cred per Praise\", \"Cred per person\",\n",
    "                                         \"period\", \"Room\", \"v1\", \"v2\", \"v3\", \"Cred per Praise\", \"Cred per person\", \"Unnamed: 12\", \"To.1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can also drop \"Avg %\" and \"Date\" (since this is duplicated in other columns.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.drop(columns = [\"Avg %\", \"Date\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We notice an issue with \"Server\" name that we perhaps should have caught earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(praise_df[\"Server\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Both \"TG\" and \"Telegram\" are used for Telegram. It's time to fix this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_TG = lambda x: \"Telegram\" if x == \"TG\" else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df[\"Server\"] = praise_df[\"Server\"].map(replace_TG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(praise_df[\"Server\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how much each Server contributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].count()/len(praise_df[\"IH per Praise\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].sum()/praise_df[\"IH per Praise\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since both \"Bot Training Ground\" and \"TEC template\" contributed less than 1%, we will remove them from the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df = praise_df[~(praise_df[\"Server\"] == \"Bot Training Ground\")]\n",
    "praise_df = praise_df[~(praise_df[\"Server\"] == \"TEC template\")]  \n",
    "praise_df = praise_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].count().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].count().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].sum().plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.groupby(\"Server\")[\"IH per Praise\"].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since we originally made \"Source\" based on Server name and we have now changed Server, we also change Source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df[\"Source\"] = praise_df[\"Server\"] + \" : \" + praise_df[\"Room-NoEmoji\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df[\"Source\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are some activities that, according to the quantiifiers, that are exceptionally great (such as \"inventing augmented bonded curves\") and thus atypical. We'd like to decide on a cutoff point, to remove these occurrences and analyze them separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_quantiles = np.quantile(praise_df[\"IH per Praise\"], [0.8,0.85,0.9,0.95,0.99])\n",
    "list_of_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The top 5% begins at approximately 4.42. This feels right to us, though we can change the quantile later if we wish. We create a new data frame that holds only exceptional data (top 5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_quant = 0.95\n",
    "exceptional_df = praise_df[praise_df[\"IH per Praise\"] >= np.quantile(praise_df[\"IH per Praise\"], cutoff_quant)]\n",
    "exceptional_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How many exceptional praises are there?\")\n",
    "print(\"There are {} praises in this exceptional data frame, which begins at the {} percentile.\".format(len(exceptional_df), cutoff_quant))\n",
    "print(\"\\n\")\n",
    "print(\"What percentage of the Impact Hours awarded come from these praises?\")\n",
    "pct_exceptional_IH =100*(exceptional_df[\"IH per Praise\"].sum()/praise_df[\"IH per Praise\"].sum())\n",
    "print(\"{} percent of the Impact Hours awarded come from this group\".format(pct_exceptional_IH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptional_df.groupby(\"Server\")[\"IH per Praise\"].count()/len(exceptional_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptional_df.groupby(\"Server\")[\"IH per Praise\"].sum()/exceptional_df[\"IH per Praise\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organizing Into Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we are interested in the word-level data, with a hope of recognizing and grouping like activities. \n",
    "\n",
    "We use a basic [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), which simply creates a new column for each word that appears in the data set, then gives each observation the number of times that word appeared. \n",
    "\n",
    "Settings:\n",
    "* input: \"content\" -- since our source is a list\n",
    "* stop_words = \"english\" -- to avoid common words like \"the\", \"and\", \"a\", etc.\n",
    "\n",
    "Settings We Did Not Use, but Could:\n",
    "* max_df: maximum document frequency -- ignore words which occur too frequently\n",
    "* min_df: minimum_document_frequency - ignore words which are very rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(input = \"content\", stop_words = 'english', binary = True, analyzer = \"word\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_encoded = vectorizer.fit_transform(praise_df[\"Reason for dishing\"].to_list())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.DataFrame(data = words_encoded.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we join this data back to the original data, so we also have context of source, date, and Impact Hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(words_df.index == praise_df.index) == len(praise_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([words_df, praise_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can use his data frame to answer questions related to the textual information in the praise, as well as date, server, and room. To give an example of what this might look like, we focus on social media, finding all messages which contain \"retweeting\" or \"mentioning\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby(\"Server\")[\"retweeting\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"retweeting\"] == 1].groupby(\"Server\")[\"IH per Praise\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"mentioning\"] == 1].groupby(\"Server\")[\"IH per Praise\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"retweeting\"] == 1].groupby(\"Month\")[\"IH per Praise\"].mean().plot.barh()\n",
    "plt.title(\"Impact Hours for retweeting by Month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"retweeting\"] == 1].groupby(\"Month\")[\"IH per Praise\"].count().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[final_df[\"retweeting\"] == 1].groupby(\"Month\")[\"IH per Praise\"].sum().plot.barh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_condition = (final_df[\"retweeting\"]== 1) | (final_df[\"mentioning\"] == 1)\n",
    "social_df = final_df[social_condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(social_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_df[\"Reason for dishing\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_and_server = pd.pivot_table(data = social_df,  values = \"IH per Praise\", index = \"Month\", \n",
    "                                  columns = \"Server\", aggfunc = 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_and_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_and_server = month_and_server.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (12, 7))\n",
    "sns.heatmap(month_and_server, cmap ='RdYlGn', linewidths = 0.30, \n",
    "            annot = True)\n",
    "ax.set_title(\"Value of Retweets and Mentions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Well, this looks strange -- why would social media activity on Telegram in December be worth twice as much as similar activity in Token Engineering Commons in April? </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_TG_df = social_df.query(\"Server == 'Telegram' & Month == 12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_TG_df[\"Reason for dishing\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_TG_df[[\"Reason for dishing\",\"IH per Praise\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style = \"color:purple\"> 1. One reason for discrepancy is obviously fair: the work of writing an article vs. the work of retweeting. So perhaps \"mentioning\" needs to be utilized more carefully.  </span>\n",
    "\n",
    "### <span style = \"color: red\"> 2. There are identical items which receive various values. This is likely a result of \"hand-editing\" by the quantifiers. In [my conversation with Griff on May 20](https://www.youtube.com/watch?v=XTlfElzjPWg), he said that validators would sometimes \"hand-edit\" the overall amount of Impact Hours that a contributor received if they felt it was not proportional to actual impact. They did this by adjusting an arbitrary row. I think we are seeing that here.  </span>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Clustering to Group Like Praise\n",
    "\n",
    "This would be a good place for someone with more expertise in clustering to come in:\n",
    "* How many clusters/categories should we make?\n",
    "* What isa good algothm?\n",
    "* How should the data be preprocessed/cleaned/embedded beforehand? (Perhaps td-idr or Doc2Vec, etc.)\n",
    "* How to use human labeling? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterer = KMeans(n_clusters = 4, n_init = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_clusters = clusterer.fit(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(clusterer.labels_==0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(clusterer.labels_==1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(clusterer.labels_==2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(clusterer.labels_==3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.loc[clusterer.labels_==0, :].sum().sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.loc[clusterer.labels_==1, :].sum().sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.loc[clusterer.labels_==2, :].sum().sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df.loc[clusterer.labels_==3, :].sum().sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.loc[clusterer.labels_==0, :][\"IH per Praise\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.loc[clusterer.labels_==1, :][\"IH per Praise\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.loc[clusterer.labels_==2, :][\"IH per Praise\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "praise_df.loc[clusterer.labels_==3, :][\"IH per Praise\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
